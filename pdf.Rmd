---
title: "Tarea 1"
author: "Mayra Samantha Cervantes Bravo - 141371"
date: "01/3/2021"
output:
  pdf_document: 
    latex_engine: xelatex
---

```{r setup, include=FALSE,results='asis'}
knitr::opts_chunk$set(echo = FALSE, fig.pos = 'H')
library(haven)
library(qwraps2)
library(summarytools)
library(devtools)
library(knitr)
library(dplyr)
library(stargazer)
library(lmtest)
library(sandwich)
library(devtools)
library(fansi)
library(RCT)
library(rstatix)
library(data.table)
library(mfx)
library(perm)
library(coin)  
library(magrittr)
library(exactRankTests)
library(powerMediation)
library(tidyverse)
library(ggeffects)
library(ggplot2)
library(EnvStats)
library(WebPower)
nam<-read_dta("Names.dta")
attach(nam)
options(knitr.table.format = "latex")
```

### Pregunta 1

La aleatorización de los nombres es relevante para el experimento  debido a que de esta forma se puede asegurar al *ceteris paribus* y así medir el "efecto puro" de la discriminación: al ser individuos "idénticos" (en sus CVs), la asignación aleatoria de nombres asegura que lo que se busca medir no esté contaminado por otros "confusores", o desbalance de las variables explicativas. Así, se muestra que la decisión de hacer *call-back* no pudo ser por razones relacionadas a características personales de los aplicantes, ya que esta fue aleatoria. Así, si los dos grupos están "balanceados" se puede medir el efecto puro de la discriminación (decisión por cómo suena el nombre), ya que se elimina el sesgo por ser diferentes desde un principio. 

Si hubieran usado información de postulantes verdaderos, no se podría asegurar que los CVs serían similares desde la perspectiva del empleador, y la decisión podría ser por las diferentes características de los grupos en las variables explicativas, por ejemplo, medias diferentes en años de educación en blancos y afro-americanos. Si este caso hipotético fuera cierto, no se podría distinguir si la decisión fue por estos factores o por discriminación: de ahí la importancia de la aleatoriedad y el balance.  

De haber seguido esa estrategia, su coeficiente de *black* tendría por variables omitidas, por lo explicado anteriormente. Si los afro-americanos tienen características (Xi's) que tienen relación negativa con probabilidad de call_back (como haber cursado la licenciatura o tener email, hipotéticamente), y estas variables tienen una relación positiva con la probabilidad de recibir *call_back*, entonces habría un sesgo negativo, donde el coeficiente de *black* sería mayor al estimador sesgado, sobreestimando el efecto de ser afro-americano en esta probabilidad. 

### Pregunta 2


Primero se generó una tabla de estadísticas descriptivas (media y desviación estándar) de las  características de los individuos en los CVs. En esta, las columnas relevantes para ver que se aleatorizó correctamente son la 2° y la 3°, que indican a los individuos con nombres blancos y afroamericanos. Podemos notar que las medias son las mismas en ambas columnas, lo que implica que no se "favoreció" a un grupo en particular: aquí se verifica el balance. Si las proporciones no fueran iguales, y un grupo tuviera "más" o "menos" de cierta característica, ya no podríamos asegurar que el efecto de discriminar está meramente por los nombres.. 

```{r,results='asis', message=FALSE,header=FALSE}
options(qwraps2_markup = "latex")
our_sum<-list("Licenciatura"=list("Licenciatura"= ~qwraps2::mean_sd(college)),
              "Años de experiencia"=list("Años de experiencia"= ~qwraps2::mean_sd(yearsexp)),
              "Experiencia militar"=list("Experiencia militar"= ~qwraps2::mean_sd(military)),
              "Email"=list("Email"= ~qwraps2::mean_sd(email)),
              "Hoyos de empleo"=list("Hoyos de empleo"= ~qwraps2::mean_sd(empholes)),
              "Honores"=list("Honores"= ~qwraps2::mean_sd(honors)),
              "Habilidades cómputo"=list("Habilidades computacionales"= ~qwraps2::mean_sd(computerskills)),
              "Habilidades especiales"=list("Habilidades especiales"= ~qwraps2::mean_sd(specialskills)))
whole1 <-summary_table(nam,our_sum)
whole2<- summary_table(nam, summaries=our_sum, by=c("black","high"))
both<-cbind(whole1,whole2)
kable(both,caption="Estadísticas descriptivas",booktabs=T)
#%>% kable_styling(position = "center")
#col.names=c("Total","Blancos","Afro-am.","Baja calidad","Alta calidad")
```
Otra forma de verificar esto es con una tabla de balance. En esta se busca no rechazar, o que las diferencias de medias no sean estadísticamente diferentes de cero. Esto se cumple para todas las variables menos *computer skills*, que tiene un *p-value* de .03; no es significativa al .01 pero sí al .05.

```{r, results='asis', message=FALSE,header=FALSE}
variables23<-data.frame(college,yearsexp,military,email,empholes,honors,
                       computerskills,specialskills,black)
tabla23<-balance_table(variables23,treatment="black")
         
stargazer(as.data.frame(tabla23),type="latex",summary=FALSE,digits=2,title="Tabla de Balance",
          covariate.labels=c( "No.","Variables", "Media control","Media tratamiento", "P-value"))
```

### Pregunta 3

### a) Pruebas de hipótesis {-}

La variable dependiente de los modelos es la probabilidad de recibir call-back, representada en una variable dicotómica donde 1 es que la recibe y 0 que no. En los modelos univariados black es la variable independiente, donde 1 es indicador de ser afro-americano y 0 de ser blanco. Todas las regresiones excepto la primera tienen errores heterocedásticos. Se busca encontrar si hay discriminación en contra de la población afroamericana. 


1. MCO (estimador de Neyman):

$CallBack_{i}=\beta_{0}+\beta_{1} Black_i +u_{i}$,

donde

$H_{0}: \tau = 0 $ vs $H_{1}: \tau < 0 $ (donde $\tau$ representa a la diferencia de medias de tratamiento y control, representada por $\beta_{Black}$

2. MCO : 

$CallBack_{i}=\beta_{0}+\beta_{1} Black_i +u_{i}$,

donde

$H_{0}: \beta_{1} = 0 $ vs $H_{1}: \beta_{1} < 0$

3. MCO donde los controles son: la dummy *female*, donde 1 es ser mujer; *high*, dummy donde 1 es que el CV es de calidad alta y 0 que es de baja y; *chicago* donde 1 indica que la información es de Chicago y 0 que es de Boston. Esto permite controlar para que el ATE sea insesgado.

$CallBack_{i}=\beta_{0}+\beta_{1} Black_i +\beta_{2} Female_i+\beta_{3} (High_i)+ \beta_{4} Chicago_i +u_{i}$,

donde

$H_{0}: \tau = 0 $ vs $H_{1}: \tau < 0 $

4. Probit sin controles:

$Pr(Y=1 \mid X) = \Phi(X'\beta)$$, donde $$ X'\beta= \beta_{0} \beta_{1} Black_i$, 

donde

$H_{0}: \beta_{1} Black_i = 0 $ vs $H_{1}: \beta_{1} Black_i < 0$

#alfredo varianza que me mando. 
#checar las regresiones porque sí debería de ser significativo.
#si sacas el promedio de todos sale el -.032???
#efecto es igual a cero. 
#hacer el mergins........ y resolver resultados.

### b) Resultados {-}

Antes de presentar la tabla de resultados, mostramos por separado al estimador de Neyman:

```{r,results='asis', message=FALSE,header=FALSE,include=FALSE}
#esto es para obtener estimadores, pero lo omitimos
stat.test<-nam %>% t_test(call_back ~ black, detailed = TRUE)
st<-as.data.frame(stat.test)
attach(st)
```

```{r,results='asis', message=FALSE,header=FALSE}
#aquí convertimos el resultado del t-test a data frame, lo transponemos y cambiamos formato
st1 <- st %>% dplyr::select(estimate, estimate1,estimate2,n1,statistic,p) %>% tibble::rownames_to_column()%>%
  pivot_longer(-rowname) %>% pivot_wider(names_from=rowname,values_from=value)
st1<-as.data.frame(st1)
rownames(st1)<-c("Valor absoluto Diferencia","P(call_back|black=0)","P(call_back|black=1)","N","t-stat","p-value")
View(st1)
st2<- subset(st1,select=-c(name))
View(st2)
knitr::kable(st2,format="latex",caption="Estimador de Neyman",booktabs=T) 
#%>% kable_styling(position="center")
```
El estimador se incorpora en la tabla de resultados en la primera columna, ya que el coeficiente de $\beta_{1} Black_i$ es equivalente a $\tau$, y sus varianzas son iguales. 

```{r,results='asis', message=FALSE,header=FALSE}
a0<-lm(call_back ~ black, data = nam)
a1<-lm(call_back ~ black, data = nam)
cov1<-coeftest(a1, vcov = vcovHC(a1, type="HC3"))
robust_se <- sqrt(diag(cov1))
b1<-lm(call_back ~ black + female + high + chicago, data = nam)
cov2<-coeftest(b1, vcov = vcovHC(b1, type="HC3"))
robust_se2 <- sqrt(diag(cov2))
f1 <- glm(call_back ~ black,  family = binomial(link = "probit"),  data = nam)
cov3<-coeftest(f1, vcov = vcovHC(f1, type="HC3"))
robust_se3 <- sqrt(diag(cov3))
stargazer(a0,a1,b1,f1, title="Modelos discriminación racial",
          type="latex", 
          header=FALSE,
          column.sep.width = "2pt", 
          font.size = "small",se=list(NULL,robust_se,robust_se2,robust_se3))
```

### d) Interpretación {-} 

Si comparamos la columna 1 y 2, que son los modelos MPL univariados, vemos que el coeficiente de *black* es negativo e igual en ambas pero significativo al .01 solo en la 1° columna, ya que en la segunda, al tener errores heterocedásticos, aumenta su varianza de .008 a .088. tiene y con signo negativo. En el caso de MCO (1) y (2), podríamos interpretarlo como "Ceteris paribus, en promedio, los afro-americanos tienen 3.2 puntos porcentuales menos de probabilidad de recibir un "call-back" que la gente blanca".

En las columnas (3) y (4), que son el MPL multivariado y el probit, notamos que en la (3), como esperábamos, el coeficiente de black no cambió, y que en el probit se mantiene el signo negativo. 

### Pregunta 4

Se evalúa la prueba de hipótesis: 

$H_{o}: CallBack_{blancos}=CallBack_{afroam} + .01$,

Con una *Fisher Exact Test*, que es una prueba de permutaciones:  

```{r,results='asis', message=FALSE,header=FALSE}
x<-call_back[black==1]
y<-call_back[black==0]
twoSamplePermutationTestLocation(x, y,
                                 alternative="two.sided",seed = 123)
```

El valor-p es igual a cero (reportado como 0). *Ho* implica que la probabilidad de recibir call-back siendo blanco es mayor a la de los afro-americanos en exactamente 1 pp. Se evalúa si el efecto de tratamiento es constante e igual a 1 pp . Rechazamos *Ho* lo que implica que se rechaza que la probabilidad de *call-back* de los blancos sea 1pp mayor que la de todos los individuos afro-americanos.

#mu1-mu2 pones constante .01 y ya. en la de twosamplepermutationtest

### Pregunta 5

Estratificamos por las siguientes variables:
- Sexo
 - Femenino
 - Masculino
- Ciudad 
 - Chicago
 - Bostom 
- Industria
    - Manufacturera
    - Transportes o comunicaciones
    - Finanzas, seguros o inmobiliaria
    - Comercio
    - Servicios personales
    - Servicios sociales
    - Otros

Obteniendo 28 combinaciones diferentes. Se presenta el efecto de discriminación por estrato, el efecto promedio de tratamiento, y este comparado con el estimador de Neyman sin estratificar. 

```{r,results='asis', message=FALSE,header=FALSE}
nam$industria=ifelse(manuf==1,1,
               ifelse(transcom==1,2,
               ifelse(bankreal==1,3,
               ifelse(trade==1,4,
               ifelse(busservice==1,5,
               ifelse(othservice==1,6,
               ifelse(missind==1,7,0)))))))
nam %<>%
  mutate(s = case_when(female == 0 & chicago == 0 & industria ==1 ~ 1,
                       female == 0 & chicago == 0 & industria ==2 ~ 2,
                       female == 0 & chicago == 0 & industria ==3 ~ 3,
                       female == 0 & chicago == 0 & industria ==4 ~ 4,
                       female == 0 & chicago == 0 & industria ==5 ~ 5,
                       female == 0 & chicago == 0 & industria ==6 ~ 6,
                       female == 0 & chicago == 0 & industria ==7 ~ 7,
                       female == 0 & chicago == 1 & industria ==1 ~ 8,
                       female == 0 & chicago == 1 & industria ==2 ~ 9,
                       female == 0 & chicago == 1 & industria ==3 ~ 10,
                       female == 0 & chicago == 1 & industria ==4 ~ 11,
                       female == 0 & chicago == 1 & industria ==5 ~ 12,
                       female == 0 & chicago == 1 & industria ==6 ~ 13,
                       female == 0 & chicago == 1 & industria ==7 ~ 14,
                       female == 1 & chicago == 0 & industria ==1 ~ 15,
                       female == 1 & chicago == 0 & industria ==2 ~ 16,
                       female == 1 & chicago == 0 & industria ==3 ~ 17,
                       female == 1 & chicago == 0 & industria ==4 ~ 18,
                       female == 1 & chicago == 0 & industria ==5 ~ 19,
                       female == 1 & chicago == 0 & industria ==6 ~ 20,
                       female == 1 & chicago == 0 & industria ==7 ~ 21,
                       female == 1 & chicago == 1 & industria ==1 ~ 22,
                       female == 1 & chicago == 1 & industria ==2 ~ 23,
                       female == 1 & chicago == 1 & industria ==3 ~ 24,
                       female == 1 & chicago == 1 & industria ==4 ~ 25,
                       female == 1 & chicago == 1 & industria ==5 ~ 26,
                       female == 1 & chicago == 1 & industria ==6 ~ 27,
                       female == 1 & chicago == 1 & industria ==7 ~ 28,
                       TRUE ~ 0))
ey11 <- nam %>%
  filter(s == 1 & black == 1) %$%
  mean(call_back)
ey10 <- nam %>%
  filter(s == 1 & black == 0) %$%
  mean(call_back)
ey21 <- nam %>%
  filter(s == 2 & black == 1) %$%
  mean(call_back)
ey20 <- nam %>%
  filter(s == 2 & black == 0) %$%
  mean(call_back)
ey31 <- nam %>%
  filter(s == 3 & black == 1) %$%
  mean(call_back)
ey30 <- nam %>%
  filter(s == 3 & black == 0) %$%
  mean(call_back)
ey41 <- nam %>%
  filter(s == 4 & black == 1) %$%
  mean(call_back)
ey40 <- nam %>%
  filter(s == 4 & black == 0) %$%
  mean(call_back)
ey51 <- nam %>%
  filter(s == 5 & black == 1) %$%
  mean(call_back)
ey50 <- nam %>%
  filter(s == 5 & black == 0) %$%
  mean(call_back)
ey61 <- nam %>%
  filter(s == 6 & black == 1) %$%
  mean(call_back)
ey60 <- nam %>%
  filter(s == 6 & black == 0) %$%
  mean(call_back)
ey71 <- nam %>%
  filter(s == 7 & black == 1) %$%
  mean(call_back)
ey70 <- nam %>%
  filter(s == 7 & black == 0) %$%
  mean(call_back)
ey81 <- nam %>%
  filter(s == 8 & black == 1) %$%
  mean(call_back)
ey80 <- nam %>%
  filter(s == 8 & black == 0) %$%
  mean(call_back)
ey91 <- nam %>%
  filter(s == 9 & black == 1) %$%
  mean(call_back)
ey90 <- nam %>%
  filter(s == 9 & black == 0) %$%
  mean(call_back)
ey101 <- nam %>%
  filter(s == 10 & black == 1) %$%
  mean(call_back)
ey100 <- nam %>%
  filter(s == 10 & black == 0) %$%
  mean(call_back)
ey111 <- nam %>%
  filter(s == 11 & black == 1) %$%
  mean(call_back)
ey110 <- nam %>%
  filter(s == 11 & black == 0) %$%
  mean(call_back)
ey121 <- nam %>%
  filter(s == 12 & black == 1) %$%
  mean(call_back)
ey120 <- nam %>%
  filter(s == 12 & black == 0) %$%
  mean(call_back)
ey131 <- nam %>%
  filter(s == 13 & black == 1) %$%
  mean(call_back)
ey130 <- nam %>%
  filter(s == 13 & black == 0) %$%
  mean(call_back)
ey141 <- nam %>%
  filter(s == 14 & black == 1) %$%
  mean(call_back)
ey140 <- nam %>%
  filter(s == 14 & black == 0) %$%
  mean(call_back)
ey151 <- nam %>%
  filter(s == 15 & black == 1) %$%
  mean(call_back)
ey150 <- nam %>%
  filter(s == 15 & black == 0) %$%
  mean(call_back)
ey161 <- nam %>%
  filter(s == 16 & black == 1) %$%
  mean(call_back)
ey160 <- nam %>%
  filter(s == 16 & black == 0) %$%
  mean(call_back)
ey171 <- nam %>%
  filter(s == 17 & black == 1) %$%
  mean(call_back)
ey170 <- nam %>%
  filter(s == 17 & black == 0) %$%
  mean(call_back)
ey181 <- nam %>%
  filter(s == 18 & black == 1) %$%
  mean(call_back)
ey180 <- nam %>%
  filter(s == 18 & black == 0) %$%
  mean(call_back)
ey191 <- nam %>%
  filter(s == 19 & black == 1) %$%
  mean(call_back)
ey190 <- nam %>%
  filter(s == 19 & black == 0) %$%
  mean(call_back)
ey201 <- nam %>%
  filter(s == 20 & black == 1) %$%
  mean(call_back)
ey200 <- nam %>%
  filter(s == 20 & black == 0) %$%
  mean(call_back)
ey211 <- nam %>%
  filter(s == 21 & black == 1) %$%
  mean(call_back)
ey210 <- nam %>%
  filter(s == 21 & black == 0) %$%
  mean(call_back)
ey221 <- nam %>%
  filter(s == 22 & black == 1) %$%
  mean(call_back)
ey220 <- nam %>%
  filter(s == 22 & black == 0) %$%
  mean(call_back)
ey231 <- nam %>%
  filter(s == 23 & black == 1) %$%
  mean(call_back)
ey230 <- nam %>%
  filter(s == 23 & black == 0) %$%
  mean(call_back)
ey241 <- nam %>%
  filter(s == 24 & black == 1) %$%
  mean(call_back)
ey240 <- nam %>%
  filter(s == 24 & black == 0) %$%
  mean(call_back)
ey251 <- nam %>%
  filter(s == 25 & black == 1) %$%
  mean(call_back)
ey250 <- nam %>%
  filter(s == 25 & black == 0) %$%
  mean(call_back)
ey261 <- nam %>%
  filter(s == 26 & black == 1) %$%
  mean(call_back)
ey260 <- nam %>%
  filter(s == 26 & black == 0) %$%
  mean(call_back)
ey271 <- nam %>%
  filter(s == 27 & black == 1) %$%
  mean(call_back)
ey270 <- nam %>%
  filter(s == 27 & black == 0) %$%
  mean(call_back)
ey281 <- nam %>%
  filter(s == 28 & black == 1) %$%
  mean(call_back)
ey280 <- nam %>%
  filter(s == 28 & black == 0) %$%
  mean(call_back)
#diferencias sobrevivir cada estrato
diff1 = ey11 - ey10
diff2 = ey21 - ey20
diff3 = ey31 - ey30
diff4 = ey41 - ey40
diff5 = ey51 - ey50
diff6 = ey61 - ey60
diff7 = ey71 - ey70
diff8 = ey81 - ey80
diff9 = ey91 - ey90
diff10 = ey101 - ey100
diff11= ey111 - ey110
diff12 = ey121 - ey120
diff13 = ey131 - ey130
diff14 = ey141 - ey140
diff15 = ey151 - ey150
diff16 = ey161 - ey160
diff17= ey171 - ey170
diff18 = ey181 - ey180
diff19 = ey191 - ey190
diff20 = ey201 - ey200
diff21 = ey211 - ey210
diff22 = ey221 - ey220
diff23 = ey231 - ey230
diff24 = ey241 - ey240
diff25 = ey251 - ey250
diff26 = ey261 - ey260
diff27 = ey271 - ey270
diff28 = ey281 - ey280
#weights
obs=nrow(nam)
wt1 <- nam %>%
  filter(s == 1 ) %$%
  nrow(.)/obs
wt2 <- nam %>%
  filter(s == 2 ) %$%
  nrow(.)/obs
wt3 <- nam %>%
  filter(s == 3 ) %$%
  nrow(.)/obs
wt4 <- nam %>%
  filter(s == 4 ) %$%
  nrow(.)/obs
wt5 <- nam %>%
  filter(s == 5 ) %$%
  nrow(.)/obs
wt6 <- nam %>%
  filter(s == 6 ) %$%
  nrow(.)/obs
wt7 <- nam %>%
  filter(s == 7 ) %$%
  nrow(.)/obs
wt8 <- nam %>%
  filter(s == 8 ) %$%
  nrow(.)/obs
wt9 <- nam %>%
  filter(s == 9 ) %$%
  nrow(.)/obs
wt10 <- nam %>%
  filter(s == 10 ) %$%
  nrow(.)/obs
wt11 <- nam %>%
  filter(s == 11 ) %$%
  nrow(.)/obs
wt12 <- nam %>%
  filter(s == 12 ) %$%
  nrow(.)/obs
wt13 <- nam %>%
  filter(s == 13 ) %$%
  nrow(.)/obs
wt14 <- nam %>%
  filter(s == 14 ) %$%
  nrow(.)/obs
wt15 <- nam %>%
  filter(s == 15 ) %$%
  nrow(.)/obs
wt16 <- nam %>%
  filter(s == 16 ) %$%
  nrow(.)/obs
wt17 <- nam %>%
  filter(s == 17 ) %$%
  nrow(.)/obs
wt18 <- nam %>%
  filter(s == 18 ) %$%
  nrow(.)/obs
wt19 <- nam %>%
  filter(s == 19 ) %$%
  nrow(.)/obs
wt20 <- nam %>%
  filter(s == 20 ) %$%
  nrow(.)/obs
wt21 <- nam %>%
  filter(s == 21 ) %$%
  nrow(.)/obs
wt22 <- nam %>%
  filter(s == 22 ) %$%
  nrow(.)/obs
wt23 <- nam %>%
  filter(s == 23 ) %$%
  nrow(.)/obs
wt24 <- nam %>%
  filter(s == 24 ) %$%
  nrow(.)/obs
wt25 <- nam %>%
  filter(s == 25 ) %$%
  nrow(.)/obs
wt26 <- nam %>%
  filter(s == 26 ) %$%
  nrow(.)/obs
wt27 <- nam %>%
  filter(s == 27 ) %$%
  nrow(.)/obs
wt28 <- nam %>%
  filter(s == 28 ) %$%
  nrow(.)/obs
wate = diff1*wt1 + diff2*wt2 + diff3*wt3 + diff4*wt4+ diff5*wt5 + diff6*wt6 + diff7*wt7 + diff8*wt8+
  diff9*wt9 + diff10*wt10 + diff11*wt11 + diff12*wt12+ diff13*wt13 + diff14*wt14 + diff15*wt15 + 
  diff16*wt16+ diff17*wt17 + diff18*wt18 + diff19*wt19 + diff20*wt20+ diff21*wt21 + diff22*wt22 + diff23*wt23 + 
  diff24*wt24+  diff25*wt25 + diff26*wt26 + diff27*wt27+diff28*wt28
Diferencias<-c(diff1,diff2,diff3,diff4,diff5,diff6,diff7,diff8,diff9,diff10,diff11,diff12,diff13,
               diff14,diff15,diff16,diff17,diff18,diff19,diff20,diff21,diff22,diff23,
               diff24,diff25,diff26,diff27,diff28 )
Estrato<-c("Hombre/Boston/Manufacturera","Hombre/Boston/Transporte o comunicaciones","Hombre/Boston/Finanzas, seguros, inmuebles","Hombre/Boston/Comercio","Hombre/Boston/Servicios personales","Hombre/Boston/Servicios sociales","Hombre/Boston/Otro",
           "Hobre/Chicago/Manufacturera","Hombre/Chicago/Transporte o comunicaciones","Hombre/Chicago/Finanzas, seguros, inmuebles","Hombre/Chicago/Comercio","Hombre/Chicago/Servicios personales","Hombre/Chicago/Servicios sociales","Hombre/Chicago/Otro",
           "Mujer/Boston/Manufacturera","Mujer/Boston/Transporte o comunicaciones","Mujer/Boston/Finanzas, seguros, inmuebles","Mujer/Boston/Comercio","Mujer/Boston/Servicios personales","Mujer/Boston/Servicios sociales","Mujer/Boston/Otro",
           "Mujer/Chicago/Manufacturera","Mujer/Chicago/Transporte o comunicaciones","Mujer/Chicago/Finanzas, seguros, inmuebles","Mujer/Chicago/Comercio","Mujer/Chicago/Servicios personales","Mujer/Boston/Servicios sociales","Mujer/Chicago/Otro")
df<-data.frame(Estrato, Diferencias, stringsAsFactors=TRUE)
kable(df, booktabs=T,digits=4,col.names = c("Estrato","Diferencia Probabilidad de call-back entre Afroamericanos y Blancos"))
#%>% kable_styling(position = "center")
```
La siguiente tabla compara estos resultados con el efecto de tratamiento sin estratificar: 

```{r,results='asis', message=FALSE,header=FALSE}
#vartau_estr<-var(call_back[black==1]/length(yiT))+var(call_back[black==0]/length(yiC))
#stargazer(wate, gate, type = "text")
```
#.0077...

### Pregunta 6

En esta sección obtenemos la media y desviación estándar de las variables de la tabla 7, y las adjuntamos a los efectos marginales de su interacción con black, cada una obtenida de una especificación de un probit diferente.

*Nota: los efectos marginales y sus varianzas se pegaron a mano en la tabla, mas están los comandos de cómo se obtuvo todo y su impresión respectiva.* 


```{r,results='asis', message=FALSE,header=FALSE}
#any req
probitmfx(call_back ~ black+req+ black*req, nam, atmean = TRUE, robust = TRUE, 
          clustervar1 = NULL, clustervar2 = NULL, start = NULL, control = list())
#0.022860 , 0.019067
#experience requirement
probitmfx(call_back ~ black+expreq+ black*expreq, nam, atmean = TRUE, robust = TRUE, 
          clustervar1 = NULL, clustervar2 = NULL, start = NULL, control = list())
#0.010691 , 0.016685
#computer req
probitmfx(call_back ~ black+compreq+ black*compreq, nam, atmean = FALSE, robust = TRUE, 
          clustervar1 = NULL, clustervar2 = NULL, start = NULL, control = list())
#.00092, 0.01600186
#comm skills
probitmfx(call_back ~ black+comreq+ black*comreq, nam, atmean = FALSE, robust = TRUE, 
          clustervar1 = NULL, clustervar2 = NULL, start = NULL, control = list())
#-0.00038614 , 0.02350449
#org skills
probitmfx(call_back ~ black+orgreq+ black*orgreq, nam, atmean = FALSE, robust = TRUE, 
          clustervar1 = NULL, clustervar2 = NULL, start = NULL, control = list())
#0.0278613,  0.0427784
#education
probitmfx(call_back ~ black+educreq+ black*educreq, nam, atmean = FALSE, robust = TRUE, 
          clustervar1 = NULL, clustervar2 = NULL, start = NULL, control = list())
#-0.0308619,  0.0210996
#total number of reqs
#creamos totreq
nam$totreq=expreq+comreq+educreq+compreq+orgreq
attach(nam)
probitmfx(call_back ~ black+totreq+ black*totreq, nam, atmean = FALSE, robust = TRUE, 
          clustervar1 = NULL, clustervar2 = NULL, start = NULL, control = list())
#0.0015161 , 0.0081261
attach(nam)
df.sum <- nam %>% dplyr::select(req, expreq, comreq, educreq, compreq, 
         orgreq,totreq) %>% 
  summarise_each(funs(mean = mean, 
                      sd = sd))
df.tidy <- df.sum %>% gather(stat, val) %>%
  separate(stat, into = c("var", "stat"), sep = "_") %>%
  spread(stat, val) %>%
  dplyr::select(mean, sd) # reorder columns
#0.022860 , 0.019067
#0.010691 , 0.016685
#.00092, 0.01600186
#-0.00038614 , 0.02350449
#0.0278613,  0.0427784
#-0.0308619,  0.0210996
#0.0015161 , 0.0081261
Requisitos<-c("Alguno","Experiencia","Habilidades computacionales","Habilidades comunicacionales",
              "Habilidades organizacionales","Educacionales","Número total")
marg.effects<-c(0.022860,0.010691,0.00092,-0.00038614,0.0278613,-0.0308619,0.0015161)
marg.eff<-round(marg.effects,digits=3)
marginal.sd<-c(0.019067,0.016685,0.01600186,0.02350449,0.0427784,0.0210996,0.0081261)
marg.sd<-round(marginal.sd,digits=3)
df.tidy$Requisitos=Requisitos
df.tidy$marg.eff=marg.eff
df.tidy$marg.sd=marg.sd
df.tidy<-df.tidy[,c(3,1,2,4,5)]
kable(df.tidy,digits=3,booktabs=T,col.names=c("Requisitos","Media","Sd","Efecto marginal","Sd efecto marginal")) 
#rtitle="Tabla 7. Efecto de requisitos en call-backs diferenciados por raza"
#%>% kable_styling(position = "center")
```

### Pregunta 7 

Planteamos una especificación para buscar evidencia de que la discriminación tiene rendimientos decrecientes respecto a la experiencia (*yearsexp*). Nuestra especificación es: 

$CallBack_{i}=\beta_{0}+\beta_{1} Black_i +\beta_{2} YearsExp_i+\beta_{3} YearsExp_{i}^2 + \beta_{4} (YearsExp_i*Black_i) + \beta_{5} (YearsExp_i*Black_i)^2 + u_{i}$

Se incluyeron los términos cuadráticos para encontrar rendimientos de los años de experiencia, e interacciones con *black* para ver si los *rendimientos de la discriminación*. Primero, observamos los resultados de la regresión:

```{r,results='asis', message=FALSE,header=FALSE}
d.3<-lm(call_back ~ black + yearsexp + I(yearsexp^2)+I(black*yearsexp)+I(black*yearsexp^2), data = nam)
stargazer(d.3, title="Experiencia y raza en Call-backs",
          type="text",
          column.labels = c("MPL"),
          header=FALSE,
          column.sep.width = "2pt", 
          font.size = "small")
```
Años de experiencia tiene una relación positiva y significativa con la probabilidad de recibir *call-back*, al igual que *yearsexp^2*, que señalaría rendimientos decrecientes de los blancos. Sin embargo,  $\beta_{5} (YearsExp_i*Black_i)^2$ tiene signo positivo y no es significativa. 

En primera instancia,  podemos ver que el rendimiento inicial de los blancos en su primer año de experiencia es positivo, mientras que el de los afro-americanos es también positivo pero menor (.011 vs .003, resultado de sumar $\beta_{2} + \beta_{4}$). 

En cuanto a las pendientes de los rendimientos de los dos grupos, la pendiente de los blancos $\beta_{3}$ es negativa pero muy pequeña (-.006, o $2*\beta_{3}$, sin embargo, la de los afro-americanos es *cero* ($\beta_{3} = -\beta_{5}$). Eso significa que los rendimientos en la probabilidad de ser llamados de vuelta dado para este grupo son constantes. Esto se ve así: 

```{r,results='asis', message=FALSE,header=FALSE}
d.3<-lm(call_back ~ black + yearsexp + I(yearsexp^2)+I(black*yearsexp)+I(black*yearsexp^2), data = nam)
nam$predsq=predict(d.3,type="response")        
black3=as.factor(black)
ggplot(nam,aes(x = yearsexp,y =predsq,color=black3)) +
  geom_point()+theme_minimal()+xlim(0,30)+ylim(0.04,.18)+labs(title="Relación años de experiencia con probabilidad de Call-back",
                      x="Años de Experiencia",y="Probabilidad de Call-back")+scale_color_discrete(name = "Black", labels = c("Blanco", "Afro-am"))
```

Si realizamos una prueba de hipótesis conjunta para ver si los rendimientos de los años de experiencia son diferentes entre blancos y afroamericanos, donde $\beta_{4}$ señala el diferencial de la ordenada de los afro-americanos y $\beta_{5}$ el diferencial de su pendiente: 


$H_{0}: \beta_{4} = 0 $ 
        \beta_{5} = 0$
        
```{r,results='asis', message=FALSE,header=FALSE}
#no me sale la prueba
#linearHypothesis(d.3, c("size=0", "expenditure=0"))
        
```
Obtenemos que



### Pregunta 8

### a) Calcular tamaño de la muestra {-}

Para obtener el tamaño de la muestra adecuado para las siguientes características:

(i) Efecto real: .0320, varianza: 0.00006 
(ii) Poder estadístico: 85%, 
(iii) Significancia: 1%, y 
(iv) División 50-50 tratamiento y control
(v) Proporción de blancos que reciben call-back: .0965 
(vi) Proporción de afro-americanos que reciben call-back: 0.06447639
(vii) Cohen's d (o efecto real estandarizado): .118

Se usó la función *SSizeLogisticBin*, la cual calcula la N para regresiones logísticas simples con variable regresora binaria. Se priorizó esta antes de otras funciones porque esta permite especificar a la $\gamma$, o la proporción de observaciones en tratamiento, además de la proporción de "éxitos" en cada grupo (control y tratamiento). Se obtuvo una n de 3762, similar al número de observaciones de Bertrand y Mullainathan, que fue de 4870. Si hacemos los calculos respectivos, obtenemos que esto implica que ellos tuvieron un poder de .9376.

```{r,results='asis', message=FALSE,header=FALSE}
SSizeLogisticBin(p1=0.09650924,p2=0.06447639,B=.5,alpha=.01,power=.85)
```

### b) Trade-off poder estadístico y proporción tratamiento y control {-}

#en ggplot puedes meter power. 

```{r,results='asis', message=FALSE,header=FALSE}
#parameter=.9 p=0.4088183
#parameter=.8 p=0.6867039
#parameter=.7 p=.8059058
#parameter=.6 p=.0.8485314
#parameter=.5 p=.85
#parameter=.4 p=0.8162238
#parameter=.3 p=0.7326352
#parameter=.2 p=0.5667912
#parameter=.1 p=0.290891
#
wp.logistic(n=3813,p0 = 0.09650924, p1 = 0.06447639,alternative="two.sided",family="Bernoulli",
            parameter=.9,power=,alpha=.01)
wp.logistic(n=3813,p0 = 0.09650924, p1 = 0.06447639,alternative="two.sided",family="Bernoulli",
            parameter=.8,power=,alpha=.01)
wp.logistic(n=3813,p0 = 0.09650924, p1 = 0.06447639,alternative="two.sided",family="Bernoulli",
            parameter=.7,power=,alpha=.01)
wp.logistic(n=3813,p0 = 0.09650924, p1 = 0.06447639,alternative="two.sided",family="Bernoulli",
            parameter=.6,power=,alpha=.01)
wp.logistic(n=3813,p0 = 0.09650924, p1 = 0.06447639,alternative="two.sided",family="Bernoulli",
            parameter=.5,power=,alpha=.01)
wp.logistic(n=3813,p0 = 0.09650924, p1 = 0.06447639,alternative="two.sided",family="Bernoulli",
            parameter=.4,power=,alpha=.01)
wp.logistic(n=3813,p0 = 0.09650924, p1 = 0.06447639,alternative="two.sided",family="Bernoulli",
            parameter=.3,power=,alpha=.01)
wp.logistic(n=3813,p0 = 0.09650924, p1 = 0.06447639,alternative="two.sided",family="Bernoulli",
            parameter=.2,power=,alpha=.01)
wp.logistic(n=3813,p0 = 0.09650924, p1 = 0.06447639,alternative="two.sided",family="Bernoulli",
            parameter=.1,power=,alpha=.01)
```

```{r,results='asis', message=FALSE,header=FALSE}
xs<-c(.1,.2,.3,.4,.5,.6,.7,.8,.9)
ys<-c(0.290891,0.5667912,0.7326352,0.8162238,.85,0.8485314,.8059058,.6867039,0.4088183)
df6<-data.frame(xs,ys)
ggplot(df6,aes(x=xs, y=ys)) +
  geom_line( color="grey") +
  geom_point(shape=21, color="black", fill="#69b3a2", size=2) +
  theme_minimal() +
  ggtitle("Trade-off poder estadístico vs proporción Tratamiento/control")
```
